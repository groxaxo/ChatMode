# ChatMode Configuration
# Copy this file to .env and update with your settings

# ============================================================================
# LLM Provider Configuration
# ============================================================================

# === OpenAI (or OpenAI-compatible API) ===
# Get your API key from https://platform.openai.com/api-keys
OPENAI_API_KEY=ollama

# === DeepSeek API ===
DEEPSEEK_API_KEY=sk-e0630d2949c348d0ad19d0707e1ac385
OPENAI_BASE_URL=http://localhost:11434
OPENAI_MODEL=hf.co/mradermacher/Mistral-Nemo-Inst-2407-12B-Thinking-Uncensored-HERETIC-HI-Claude-Opus-GGUF:IQ4_XS

# === Ollama (Local LLM) ===
# Install: https://ollama.com
# Pull models: ollama pull llama3.2:3b
OLLAMA_BASE_URL=http://localhost:11434

# ============================================================================
# Embedding Configuration (for semantic memory)
# ============================================================================

# Provider: "ollama" or "openai"
EMBEDDING_PROVIDER=ollama

# === Ollama Embeddings (Recommended for local) ===
EMBEDDING_MODEL=nomic-embed-text
EMBEDDING_BASE_URL=http://localhost:11434
EMBEDDING_API_KEY=ollama

# === OpenAI Embeddings (Cloud) ===
# EMBEDDING_PROVIDER=openai
# EMBEDDING_MODEL=text-embedding-3-small
# EMBEDDING_BASE_URL=https://api.openai.com/v1
# EMBEDDING_API_KEY=sk-your-key-here

# ============================================================================
# Text-to-Speech (TTS) Configuration
# ============================================================================

# Enable/disable voice synthesis
TTS_ENABLED=false

# === OpenAI TTS ===
TTS_BASE_URL=https://api.openai.com/v1
TTS_API_KEY=sk-your-key-here
TTS_MODEL=tts-1
# Available voices: alloy, echo, fable, onyx, nova, shimmer
TTS_VOICE=alloy

# === Local TTS (Optional) ===
# TTS_BASE_URL=http://localhost:5002/v1
# TTS_API_KEY=not-needed

# Output directory for generated audio files
TTS_OUTPUT_DIR=./tts_out

# ============================================================================
# Storage Configuration
# ============================================================================

# ChromaDB vector database directory
CHROMA_DIR=./data/chroma

# Database URL (SQLite, PostgreSQL, MySQL)
DATABASE_URL=sqlite:///./data/chatmode.db

# For PostgreSQL in production:
# DATABASE_URL=postgresql://user:password@localhost:5432/chatmode

# ============================================================================
# Conversation Settings
# ============================================================================

# Maximum tokens in context window
MAX_CONTEXT_TOKENS=32000

# Maximum tokens per agent response
MAX_OUTPUT_TOKENS=512

# Number of semantic memories to retrieve per query
MEMORY_TOP_K=5

# Maximum recent messages to include in context
HISTORY_MAX_MESSAGES=20

# LLM temperature (0.0=deterministic, 2.0=very creative)
TEMPERATURE=0.9

# Delay between agent responses (seconds)
SLEEP_SECONDS=15

# ============================================================================
# Admin & Debug Settings
# ============================================================================

# Use LLM to auto-generate debate topics
ADMIN_USE_LLM=true

# Optional: Pre-set topic (overrides prompt and LLM generation)
ADMIN_TOPIC=

# Enable verbose logging
VERBOSE=true
DEBUG_MODE=true
LOG_LEVEL=DEBUG

# ============================================================================
# Security (Production Only)
# ============================================================================

# Secret key for JWT signing (generate with: openssl rand -hex 32)
SECRET_KEY=change-this-in-production

# CORS allowed origins (comma-separated, use * for development only)
ALLOWED_ORIGINS=*

# For production, set specific origins:
# ALLOWED_ORIGINS=https://yourdomain.com,https://app.yourdomain.com

# ============================================================================
# CrewAI Compatibility (Optional)
# ============================================================================

# Ollama embeddings for CrewAI agents
EMBEDDINGS_OLLAMA_MODEL_NAME=nomic-embed-text
EMBEDDINGS_OLLAMA_BASE_URL=http://100.85,200.51:11434

# ============================================================================
# Frontend Configuration (Optional)
# ============================================================================

# Custom frontend directory (if not using default)
# FRONTEND_DIR=/path/to/custom/frontend
